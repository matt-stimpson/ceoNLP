{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f709d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like main results, reads in raw text (ocr-ed pdfs of Wall Street Journal and New York Times articles about \n",
    "#      CEO announcements), cleans text, constructs features (tfidf scores of ngrams), tunes hyperparameters, and\n",
    "#      fits classifiers. Here, in addition to SVMs and random forests, I also fit an XGBoost classifier.\n",
    "#\n",
    "#      The goal is to compare (1) the stability (correlations) of feature importance scores and (2) accuracies\n",
    "#      across these three classifiers. (Unlike the main results, I focus here only on the full sample period \n",
    "#      of CEO hires, 1950-2015.)\n",
    "#\n",
    "#      The main finding is that the XGBoost classifier shows similar accuracy to the other classifiers \n",
    "#      but produces feature importance scores that are more variable (in other words, it's harder to summarize \n",
    "#      how xgboost makes its predictions, i.e., which ngrams it uses to distinguish outside and inside CEO hires.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155e29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as met   \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk import word_tokenize, sent_tokenize  \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac66592",
   "metadata": {},
   "source": [
    "# Prepare texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbc5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "df_prelim = pd.read_csv(\"ceo_articles.csv\")\n",
    "df_prelim = df_prelim.rename(columns = {\"text\": \"raw_text\"}) # preserve raw text for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a680a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE UNWANTED MATERIAL FROM BEGINNING AND END OF ARTICLES\n",
    "\n",
    "def clip_front_junk(string):\n",
    "    \"\"\"Read in article as string and remove unwanted material at beginning (headers, proquest info, etc).\"\"\"\n",
    "    s_check = string.lower()\n",
    "    if \"abstract\" in s_check:\n",
    "        string = string[s_check.index(\"abstract\") + 8:]\n",
    "        s_check = s_check[s_check.index(\"abstract\") + 8:]\n",
    "        return string[s_check.index(\"full text\") + 9:]\n",
    "    elif \"full text\" in s_check:\n",
    "        return string[s_check.index(\"full text\") + 9:]\n",
    "    elif \"proquest\" in s_check:\n",
    "        return string[s_check.index(\"proquest\") + 8:]\n",
    "    elif \"wall street journal\" in s_check:\n",
    "        return string[s_check.index(\"wall street journal\") + 19:]\n",
    "    elif \"new york times\" in s_check:\n",
    "        return string[s_check.index(\"new york times\") + 19:]\n",
    "    else:\n",
    "        return string\n",
    "    \n",
    "def clip_end_junk(string):\n",
    "    \"\"\"Read in article as string and remove unwanted material at end (copywrite notice, proquest info, etc).\"\"\"\n",
    "    s_check = string.lower()\n",
    "    if \"credit:\" in s_check:\n",
    "        string = string[:s_check.index(\"credit:\")]\n",
    "    if \"subject:\" in s_check:\n",
    "        string = string[:s_check.index(\"subject:\")]\n",
    "    if \"details subject\" in s_check:\n",
    "        string = string[:s_check.index(\"details subject\")]\n",
    "    if \"issn\" in s_check:\n",
    "        string = string[:s_check.index(\"issn\")]\n",
    "    return string\n",
    "\n",
    "df_prelim['text'] = df_prelim.raw_text.apply(clip_front_junk).apply(clip_end_junk)\n",
    "\n",
    "#won't clip front material if it cuts out most of the article (usually due to bad OCR)\n",
    "df_prelim['len_text'] = df_prelim.text.map(str.split).map(len)\n",
    "df_prelim.loc[df_prelim.len_text < 25, 'text'] = df_prelim.raw_text\n",
    "df_prelim = df_prelim.drop(['len_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d18216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORE CLEANING\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"General cleaning of text, mostly replacements that need to be made.\"\"\"\n",
    "    # remove hyphens at end of line\n",
    "    text = text.replace(\"- \", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    # remove line at end of every photocopied page\n",
    "    text = text.replace(\"Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.\", \"\")\n",
    "    # some prominent typos\n",
    "    text = text.replace(\"gen eral\", \"general\")\n",
    "    text = text.replace(\"chatrman\", \"chairman\")\n",
    "    text = text.replace(\"sald\", \"said\")\n",
    "    text = text.replace(\"ta\", \"to\")\n",
    "    text = text.replace(\"retoiling\", \"retailing\")\n",
    "    text = text.replace(\"stotement\", \"statement\")\n",
    "    return text.strip()\n",
    "\n",
    "df_prelim['text'] = df_prelim.text.map(clean)   \n",
    "\n",
    "def turnaround(text):   \n",
    "    \"\"\"Based on close readings, I know there are a lot of ways to say this. Basically a corpus-specific lemma.\"\"\"\n",
    "    tokens = text.split()\n",
    "    for idx, word in enumerate(tokens.copy()[:-1]):\n",
    "        if word.startswith(\"turn\") and tokens[idx + 1] == \"around\":\n",
    "            tokens[idx] = \"turnaround\"\n",
    "    text = ' '.join(tokens)\n",
    "    text = text.replace(\"turnaround around\", \"turnaround\")\n",
    "    return text.strip()\n",
    "\n",
    "def losangeles(text):   \n",
    "    \"\"\"Another corpus-specific lemma. Here particularly wanted to avoid multiple occurences of uni/bigrams.\"\"\"\n",
    "    tokens = text.split()\n",
    "    for idx, word in enumerate(tokens.copy()[:-1]):\n",
    "        if tokens[idx] == \"Los\" and tokens[idx + 1] == \"Angeles\":\n",
    "            tokens[idx] = \"losangeles\"\n",
    "    text = ' '.join(tokens)\n",
    "    text = text.replace(\"losangeles Angeles\", \"losangeles\")\n",
    "    return text.strip()\n",
    "\n",
    "df_prelim['text'] = df_prelim.text.apply(clean).apply(turnaround).apply(losangeles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c15bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISOLATE SENTENCES ABOUT INCOMING CEO: FIRST SPLIT INTO SENTENCES AND GET CEO LAST NAME\n",
    "\n",
    "df_prelim['sentences'] = df_prelim.text.map(sent_tokenize)\n",
    "\n",
    "def extract_CEO_lastname(string):\n",
    "    name = string.split()\n",
    "    if name[-1] == \"Jr.\" or name[-1] == \"Jr\" or name[-1] == \"II\" or name[-1] == \"III\":\n",
    "        if name[-2][-1] == \",\":\n",
    "            return name[-2][:-1]\n",
    "        else:\n",
    "            return name[-2]\n",
    "    else:\n",
    "        return name[-1]\n",
    "\n",
    "df_prelim['CEO_lastname'] = df_prelim.CEO.map(extract_CEO_lastname)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851db201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW IDENTIFY CEO SENTENCES\n",
    "\n",
    "def CEO_match_yn(sentence, ceo_lastname):\n",
    "    if ceo_lastname in sentence:\n",
    "        return True\n",
    "    for w in sentence.split():\n",
    "        char_match = 0\n",
    "        w2 = w[:]\n",
    "        for c in ceo_lastname:\n",
    "            if c in w2:\n",
    "                char_match += 1\n",
    "                idx = w2.find(c)\n",
    "                w2 = w2[:idx] + w2[idx + 1:]\n",
    "        match_pct = char_match / len(ceo_lastname)\n",
    "        if match_pct >= .5 and ceo_lastname[0] == w[0] and ceo_lastname[-1] == w[-1]:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def CEO_sentences(sentences, ceo_lastname):\n",
    "    ceo_sentences = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if CEO_match_yn(sent, ceo_lastname):\n",
    "            ceo_sentences.append(sent)\n",
    "        elif re.search(\"(^|[^a-z])he[^a-z]\", sent) and ceo_lastname in sentences[i - 1]:\n",
    "            ceo_sentences.append(sent)\n",
    "        elif re.search(\"(^|[^a-z])him[^a-z]\", sent) and ceo_lastname in sentences[i - 1]:\n",
    "            ceo_sentences.append(sent)\n",
    "        elif re.search(\"(^|[^a-z])his[^a-z]\", sent) and ceo_lastname in sentences[i - 1]:\n",
    "            ceo_sentences.append(sent)\n",
    "        elif re.search(\"(^|[^a-z])she[^a-z]\", sent) and ceo_lastname in sentences[i - 1]:\n",
    "            ceo_sentences.append(sent)\n",
    "        elif re.search(\"(^|[^a-z])her[^a-z]\", sent) and ceo_lastname in sentences[i - 1]:\n",
    "            ceo_sentences.append(sent)\n",
    "    return ceo_sentences\n",
    "\n",
    "df_prelim['ceo_sentences_list'] = list(map(CEO_sentences, df_prelim.sentences, df_prelim.CEO_lastname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2177eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATENATE CEO SENTENCES AND REMOVE MISSING DATA\n",
    "\n",
    "df_prelim['text_ceo'] = df_prelim.ceo_sentences_list.map(' '.join)\n",
    "\n",
    "#print(len(df_prelim[df_prelim.text_ceo == \"\"])) #14 records to drop\n",
    "df = df_prelim[df_prelim.text_ceo != \"\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3ac81",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44efbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD VARIABLES FOR PERIOD\n",
    "\n",
    "df['year10'] = df.year.div(10).map(np.floor).map(lambda x: x*10).map(int)\n",
    "\n",
    "df['year_cat'] = df.year10\n",
    "df.year_cat = df.year_cat.replace(1950, 1980)\n",
    "df.year_cat = df.year_cat.replace(1960, 1980)\n",
    "df.year_cat = df.year_cat.replace(1970, 1980)\n",
    "df.year_cat = df.year_cat.replace(2010, 2000)\n",
    "df.at[df.index[df.year == 2000], 'year_cat'] = 1990\n",
    "\n",
    "df['period_out'] = 1\n",
    "df.at[df.index[(df.outside_hire == 1) & (df.year_cat == 1980)], 'period_out'] = 2\n",
    "df.at[df.index[(df.outside_hire == 0) & (df.year_cat == 1990)], 'period_out'] = 3\n",
    "df.at[df.index[(df.outside_hire == 1) & (df.year_cat == 1990)], 'period_out'] = 4\n",
    "df.at[df.index[(df.outside_hire == 0) & (df.year_cat == 2000)], 'period_out'] = 5\n",
    "df.at[df.index[(df.outside_hire == 1) & (df.year_cat == 2000)], 'period_out'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3931b125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Data  1104\n",
      "Size of Test Data  276\n"
     ]
    }
   ],
   "source": [
    "# SPLIT INTO TRAINING AND TESTING SETS\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.text_ceo,\n",
    "                                                    df.outside_hire,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=df.period_out)\n",
    "print('Size of Training Data ', X_train.shape[0])\n",
    "print('Size of Test Data ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66172a0",
   "metadata": {},
   "source": [
    "# Feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478f63e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP WORDS\n",
    "\n",
    "basic_stopwords = STOP_WORDS # from spacy\n",
    "basic_stopwords.add(\"going\") # only shows up as synonym with \"will\"\n",
    "#print(len(basic_stopwords)) # 327\n",
    "\n",
    "# remove ceo and firm names\n",
    "ceo_names = set([item for sublist in df.CEO.apply(str.lower).apply(str.split) for item in sublist])\n",
    "firm_names = set([item for sublist in df.Company_ID.apply(str.lower).apply(str.split) for item in sublist])\n",
    "\n",
    "# add back in some important words removed as part of firm names\n",
    "keep_names = set(['bank', 'bankers', 'banking', 'insurance', 'financial', 'good', \n",
    "                    'business', 'company', 'companies', 'commercial', 'computer', 'information', \n",
    "                    'industries', 'international', 'manufacturing', 'manufacturers', \n",
    "                    'natural', 'new', 'producing', 'products','regulator', 'solutions', 'trust', 'young'])\n",
    "\n",
    "added_stopwords = ceo_names.union(firm_names)\n",
    "added_stopwords.add(\"mr\") # to avoid, for instance, \"said mr\" in addition to \"said\"\n",
    "added_stopwords.add((\"proquest\", \"historical\", \"newspapers\")) # meaningless proquest info\n",
    "added_stopwords = set([w for w in added_stopwords if w not in keep_names])\n",
    "#print(len(added_stopwords)) # 1248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc3b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF SCORES\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    NGRAM_RANGE = (1, 4)    \n",
    "    unigrams = word_tokenize(remove_punctuation(doc))\n",
    "    tokens = unigrams\n",
    "    for n in range((NGRAM_RANGE[0] + 1), (NGRAM_RANGE[1] + 1)):\n",
    "        ngrams = [' '.join(tuple) for tuple in zip(*[unigrams[i:] for i in range(n)])]\n",
    "        tokens = tokens + ngrams\n",
    "    final_tokens = []\n",
    "    for t in tokens:\n",
    "        t_split = t.split()\n",
    "        if t_split[0] not in basic_stopwords:\n",
    "            if t_split[-1] not in basic_stopwords:\n",
    "                if len(added_stopwords.intersection(t_split)) == 0:\n",
    "                    final_tokens.append(t)\n",
    "    return final_tokens\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    s = s.replace(\"'s\", \"\")\n",
    "    s = s.replace(\"`s\", \"\")\n",
    "    s = s.replace(\"’s\", \"\")\n",
    "    return s.translate(str.maketrans('', '', string.punctuation + '”“‘’—'))\n",
    "\n",
    "tfidf_sklearn = TfidfVectorizer(tokenizer=my_tokenizer, min_df=25, max_df=0.7) # high min_df to drop firm or ceo names\n",
    "tfidf_scores = tfidf_sklearn.fit_transform(df.text_ceo)\n",
    "#tfidf_scores.shape # 1,106 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e13c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PERIOD SUBSETS FOR TRAIN/TEST SETS \n",
    "\n",
    "#train\n",
    "X_train_tf = tfidf_sklearn.transform(X_train)\n",
    "\n",
    "tf_train = pd.DataFrame(X_train_tf.toarray(), columns = tfidf_sklearn.get_feature_names_out())\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_train_df['year_cat'] = df.year_cat # matches based on index\n",
    "tf_train['year_cat'] = X_train_df.reset_index()['year_cat']\n",
    "tf_train['outside_hire'] = Y_train.reset_index()['outside_hire']\n",
    "\n",
    "X_train_pre1990 = tf_train[tf_train.year_cat==1980].drop(['year_cat', 'outside_hire'], axis=1)\n",
    "Y_train_pre1990 = tf_train[tf_train.year_cat==1980].outside_hire\n",
    "X_train_1990s = tf_train[tf_train.year_cat==1990].drop(['year_cat', 'outside_hire'], axis=1)\n",
    "Y_train_1990s = tf_train[tf_train.year_cat==1990].outside_hire\n",
    "X_train_post2000 = tf_train[tf_train.year_cat==2000].drop(['year_cat', 'outside_hire'], axis=1)\n",
    "Y_train_post2000 = tf_train[tf_train.year_cat==2000].outside_hire\n",
    "\n",
    "\n",
    "#test\n",
    "X_test_tf = tfidf_sklearn.transform(X_test)\n",
    "\n",
    "tf_test = pd.DataFrame(X_test_tf.toarray(), columns = tfidf_sklearn.get_feature_names_out())\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_test_df['year_cat'] = df.year_cat # matches based on index\n",
    "tf_test['year_cat'] = X_test_df.reset_index()['year_cat']\n",
    "tf_test['outside_hire'] = Y_test.reset_index()['outside_hire']\n",
    "\n",
    "X_test_pre1990 = tf_test[tf_test.year_cat==1980].drop(['year_cat', 'outside_hire'], axis=1)\n",
    "Y_test_pre1990 = tf_test[tf_test.year_cat==1980].outside_hire\n",
    "X_test_1990s = tf_test[tf_test.year_cat==1990].drop(['year_cat', 'outside_hire'], axis=1)\n",
    "Y_test_1990s = tf_test[tf_test.year_cat==1990].outside_hire\n",
    "X_test_post2000 = tf_test[tf_test.year_cat==2000].drop(['year_cat', 'outside_hire'], axis=1)\n",
    "Y_test_post2000 = tf_test[tf_test.year_cat==2000].outside_hire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb6672",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9d19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCE DATA THROUGH UNDERSAMPLING\n",
    "# (Note: SMOTE oversampling is less appropriate for sparse data like text ngrams)\n",
    "\n",
    "N_train = Y_train[Y_train == 1].sum() \n",
    "df_temp = pd.DataFrame(X_train_tf.toarray())\n",
    "df_temp['outside_hire'] = Y_train.reset_index()['outside_hire']\n",
    "df_temp_outs = df_temp[df_temp.outside_hire == 1]\n",
    "df_temp_ins = df_temp[df_temp.outside_hire == 0].sample(N_train, random_state=0)\n",
    "df_balanced = pd.concat([df_temp_outs, df_temp_ins])\n",
    "X_tr_bal = df_balanced.drop(['outside_hire'], axis=1)\n",
    "Y_tr_bal = df_balanced.outside_hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb0fecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search  {'C': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.803020</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.759466</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.759466</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.633217</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score                          params\n",
       "1                1         0.803020    {'C': 1, 'kernel': 'linear'}\n",
       "2                2         0.759466   {'C': 10, 'kernel': 'linear'}\n",
       "3                2         0.759466  {'C': 100, 'kernel': 'linear'}\n",
       "0                4         0.633217  {'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM HYPERPARAMETER TUNING USING GRID SEARCH\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'kernel': ['linear']\n",
    "}\n",
    "grid = GridSearchCV(SVC(random_state=0), param_grid, refit=False, cv=5, scoring='accuracy')\n",
    "grid.fit(X_tr_bal, Y_tr_bal)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "print(\"Best alpha parameter identified by grid search \", best_params)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "gridsearch_results = pd.DataFrame(grid.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "                    'params']].sort_values(by=['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4cc474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search  {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.778862</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.769338</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.759582</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.759350</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.750174</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750058</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750058</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.749942</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.745412</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.745064</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>0.740883</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>0.740534</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "0                 1         0.778862   \n",
       "1                 2         0.769338   \n",
       "13                3         0.759582   \n",
       "2                 4         0.759350   \n",
       "12                5         0.750174   \n",
       "6                 6         0.750058   \n",
       "19                6         0.750058   \n",
       "4                 8         0.749942   \n",
       "8                 9         0.745412   \n",
       "5                10         0.745064   \n",
       "18               11         0.740883   \n",
       "7                12         0.740534   \n",
       "\n",
       "                                                              params  \n",
       "0    {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 50}  \n",
       "1   {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "13     {'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "2   {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}  \n",
       "12      {'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}  \n",
       "6       {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 50}  \n",
       "19    {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "4   {'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}  \n",
       "8      {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}  \n",
       "5   {'max_depth': None, 'max_features': 'log2', 'n_estimators': 200}  \n",
       "18     {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 50}  \n",
       "7      {'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF HYPERPARAMETER TUNING USING GRID SEARCH\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 3, 5, 10]\n",
    "}\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, refit=False, cv=5, scoring='accuracy')\n",
    "grid.fit(X_tr_bal, Y_tr_bal)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "print(\"Best alpha parameter identified by grid search \", best_params)\n",
    "\n",
    "gridsearch_results = pd.DataFrame(grid.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "                    'params']].sort_values(by=['rank_test_score'])[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ec5240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search  {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.745180</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.740418</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.740302</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.740186</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.735772</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0.735656</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.730778</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>0.730778</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.730778</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.730662</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11</td>\n",
       "      <td>0.726016</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>{'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "4                 1         0.745180   \n",
       "2                 2         0.740418   \n",
       "5                 3         0.740302   \n",
       "14                4         0.740186   \n",
       "12                5         0.735772   \n",
       "13                6         0.735656   \n",
       "7                 7         0.730778   \n",
       "16                8         0.730778   \n",
       "15                8         0.730778   \n",
       "24               10         0.730662   \n",
       "25               11         0.726016   \n",
       "17               12         0.725900   \n",
       "\n",
       "                                                         params  \n",
       "4   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}  \n",
       "2   {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}  \n",
       "5   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200}  \n",
       "14  {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200}  \n",
       "12   {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 50}  \n",
       "13  {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100}  \n",
       "7   {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100}  \n",
       "16  {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 100}  \n",
       "15   {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 50}  \n",
       "24   {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 50}  \n",
       "25  {'learning_rate': 0.3, 'max_depth': 9, 'n_estimators': 100}  \n",
       "17  {'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBOOST HYPERPARAMETER TUNING USING GRID SEARCH\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "grid = GridSearchCV(XGBClassifier(random_state=0), param_grid, refit=False, cv=5, scoring='accuracy')\n",
    "grid.fit(X_tr_bal, Y_tr_bal)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "print(\"Best alpha parameter identified by grid search \", best_params)\n",
    "\n",
    "gridsearch_results = pd.DataFrame(grid.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "                    'params']].sort_values(by=['rank_test_score'])[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b67d45",
   "metadata": {},
   "source": [
    "# Train classifiers and bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65cc68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT DATA (ONLY USING TOTAL PERIOD HERE)\n",
    "\n",
    "X_input_train = pd.DataFrame(X_train_tf.toarray())\n",
    "Y_input_train = Y_train\n",
    "X_input_test = pd.DataFrame(X_test_tf.toarray())\n",
    "Y_input_test = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf27f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET RANDOM SEEDS TO MAKE BOOTSTRAPPING REPLICABLE\n",
    "\n",
    "#seeds = [random.randint(0,1000000) for _ in range(100)]\n",
    "#print(seeds)\n",
    "seeds = [68205, 944716, 279319, 900751, 717488, 230310, 700563, 35648, \n",
    "        197274, 27083, 662368, 333356, 675971, 533482, 958546, 567334, \n",
    "        872298, 230929, 259618, 98065, 892905, 655327, 991298, 9426, \n",
    "        130288, 933858, 127716, 856209, 172686, 293803, 758790, 510045, \n",
    "        534425, 296243, 832123, 616404, 867188, 544862, 219853, 104131, \n",
    "        763319, 941494, 402384, 183838, 569661, 669144, 349585, 844692, \n",
    "        188662, 254168, 523485, 665488, 659273, 744117, 165509, 75766, \n",
    "        442257, 235121, 298426, 282483, 812921, 911418, 865758, 319980, \n",
    "        347712, 290291, 789076, 224440, 195829, 879757, 648964, 433458, \n",
    "        473982, 81785, 98720, 168945, 520238, 3127, 511821, 702424, 65407, \n",
    "        101516, 824661, 585764, 836377, 442649, 690597, 500534, 959700, \n",
    "        117599, 662650, 562916, 89803, 818856, 803400, 622335, 350794, 135974, 282290, 752710]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb20a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT CLASSIFIERS USING UNDERSAMPLING AND BOOTSTRAPPING\n",
    "# (Note: SMOTE oversampling is less appropriate for sparse data like text ngrams)\n",
    "\n",
    "coef_svm = []\n",
    "coef_rf = []\n",
    "coef_xgb = []\n",
    "acc_svm = []\n",
    "acc_rf = []\n",
    "acc_xgb = []\n",
    "\n",
    "N_train = Y_input_train[Y_input_train == 1].sum()\n",
    "N_test = Y_input_test[Y_input_test == 1].sum()\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    # balance training data\n",
    "    df_temp_train = X_input_train.reset_index(drop=True)\n",
    "    df_temp_train['outside_hire'] = Y_input_train.reset_index()['outside_hire']\n",
    "    df_temp_train_outs = df_temp_train[df_temp_train.outside_hire == 1]\n",
    "    df_temp_train_ins = df_temp_train[df_temp_train.outside_hire == 0].sample(N_train, random_state=seed)\n",
    "    df_balanced_train = pd.concat([df_temp_train_outs, df_temp_train_ins])\n",
    "    df_balanced_train = df_balanced_train.sample(frac=1, random_state=seed) \n",
    "    X_bal_train = df_balanced_train.drop(['outside_hire'], axis=1)\n",
    "    Y_bal_train = df_balanced_train.outside_hire\n",
    "\n",
    "    # balance testing set\n",
    "    df_temp_test = X_input_test.reset_index(drop=True)\n",
    "    df_temp_test['outside_hire'] = Y_input_test.reset_index()['outside_hire']\n",
    "    df_temp_test_outs = df_temp_test[df_temp_test.outside_hire == 1]\n",
    "    df_temp_test_ins = df_temp_test[df_temp_test.outside_hire == 0].sample(N_test, random_state=seed)\n",
    "    df_balanced_test = pd.concat([df_temp_test_outs, df_temp_test_ins])\n",
    "    df_balanced_test = df_balanced_test.sample(frac=1, random_state=seed) \n",
    "    X_bal_test = df_balanced_test.drop(['outside_hire'], axis=1)\n",
    "    Y_bal_test = df_balanced_test.outside_hire    \n",
    "    \n",
    "    # SVM\n",
    "    svc = SVC(kernel=\"linear\", C=1, random_state=seed)\n",
    "    svc.fit(X_bal_train, Y_bal_train)\n",
    "    Y_pred_svc = svc.predict(X_bal_test)\n",
    "    acc_svm.append(met.accuracy_score(Y_bal_test, Y_pred_svc))\n",
    "    coef_svm.append(list(svc.coef_[0]))\n",
    "    \n",
    "    # RF\n",
    "    rf = RandomForestClassifier(n_estimators=50, max_features='sqrt', max_depth=None, random_state=seed)\n",
    "    rf.fit(X_bal_train, Y_bal_train)\n",
    "    Y_pred_rf = rf.predict(X_bal_test)\n",
    "    acc_rf.append(met.accuracy_score(Y_bal_test, Y_pred_rf))\n",
    "    coef_rf.append(list(rf.feature_importances_))\n",
    "    \n",
    "    # XGB\n",
    "    xgb = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=seed)\n",
    "    xgb.fit(X_bal_train, Y_bal_train)\n",
    "    Y_pred_xgb = xgb.predict(X_bal_test)\n",
    "    acc_xgb.append(met.accuracy_score(Y_bal_test, Y_pred_xgb))\n",
    "    coef_xgb.append(list(xgb.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70bea0",
   "metadata": {},
   "source": [
    "# Results: Correlations of Feature Importances; Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a6efa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6633258497185003\n",
      "0.7312071871232358\n",
      "0.37738301930050455\n"
     ]
    }
   ],
   "source": [
    "# CORRELATIONS (I.E., STABILITY) OF FEATURE IMPORTANCE SCORES\n",
    "\n",
    "#feature importances\n",
    "vocabulary = tfidf_sklearn.get_feature_names_out()\n",
    "coef_svm_df = pd.DataFrame(coef_svm, columns=vocabulary).transpose()\n",
    "coef_rf_df = pd.DataFrame(coef_rf, columns=vocabulary).transpose()\n",
    "coef_xgb_df = pd.DataFrame(coef_xgb, columns=vocabulary).transpose()\n",
    "\n",
    "#edit RF & XGB feature importances: separate those helping predict outside hires vs those helping predict inside hires\n",
    "tf_scores = X_train_tf[Y_train==1].mean(axis=0) - X_train_tf[Y_train==0].mean(axis=0)\n",
    "tf_scores_dichot = np.where(tf_scores > 0, 1, -1)\n",
    "coef_rf_df = coef_rf_df.multiply(tf_scores_dichot.transpose(), axis=0)\n",
    "coef_xgb_df = coef_xgb_df.multiply(tf_scores_dichot.transpose(), axis=0)\n",
    "\n",
    "#correlations\n",
    "print(coef_svm_df.corr().mean().mean()) # 0.66\n",
    "print(coef_rf_df.corr().mean().mean()) # 0.73\n",
    "print(coef_xgb_df.corr().mean().mean()) # 0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fac26102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm</th>\n",
       "      <th>rand_forests</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.776731</td>\n",
       "      <td>0.788077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.044905</td>\n",
       "      <td>0.049199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.826923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              svm  rand_forests     xgboost\n",
       "count  100.000000    100.000000  100.000000\n",
       "mean     0.810000      0.776731    0.788077\n",
       "std      0.044519      0.044905    0.049199\n",
       "min      0.711538      0.653846    0.673077\n",
       "25%      0.783654      0.750000    0.750000\n",
       "50%      0.807692      0.769231    0.788462\n",
       "75%      0.846154      0.807692    0.826923\n",
       "max      0.903846      0.884615    0.903846"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCURACIES\n",
    "\n",
    "acc = pd.DataFrame({'svm': acc_svm})\n",
    "acc['rand_forests'] = acc_rf\n",
    "acc['xgboost'] = acc_xgb\n",
    "\n",
    "acc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
